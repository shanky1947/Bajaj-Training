{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMtJhx7kJwKY",
        "outputId": "413d59d9-aa72-462c-eb06-7ff6ea614f80"
      },
      "id": "sMtJhx7kJwKY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 43.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=03bb7e1c0163639bc6950a7d47cf2e42c086fdf906b5a7acbd7abc80ee064399\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5a9569",
      "metadata": {
        "id": "ee5a9569"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc3501d",
      "metadata": {
        "id": "1bc3501d"
      },
      "source": [
        "## RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c4eb22",
      "metadata": {
        "id": "d4c4eb22"
      },
      "source": [
        "### i) Parallelized\n",
        "### ii) Dataset in an storage system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e8eddd3",
      "metadata": {
        "id": "8e8eddd3"
      },
      "outputs": [],
      "source": [
        "# i) Parallelized\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c67ddb",
      "metadata": {
        "id": "51c67ddb"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('Practise').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "814ee234",
      "metadata": {
        "id": "814ee234"
      },
      "outputs": [],
      "source": [
        "df = spark.sparkContext.parallelize([(12,35,'abc'),\n",
        "                                   (41,58, 'def'),\n",
        "                                   (23,32, 'ghi')]).toDF(['col1','col2','col3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed92a69",
      "metadata": {
        "id": "9ed92a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df31c7e-2392-40e4-a18d-496f41aec5f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.show of DataFrame[col1: bigint, col2: bigint, col3: string]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4cf2e3",
      "metadata": {
        "id": "ba4cf2e3"
      },
      "outputs": [],
      "source": [
        "#using createDataFrame() function\n",
        "student = spark.createDataFrame([\n",
        "    ('00901', 'abhi', '70%', 'EC'),('00902','shash','80%','VC')\n",
        "],['RollNum','Name','Precentage','Department'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a98dfe0",
      "metadata": {
        "id": "8a98dfe0",
        "outputId": "3e080bd5-843f-4ab2-907b-4507893d03cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+----------+\n",
            "|RollNum| Name|Precentage|Department|\n",
            "+-------+-----+----------+----------+\n",
            "|  00901| abhi|       70%|        EC|\n",
            "|  00902|shash|       80%|        VC|\n",
            "+-------+-----+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "student.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94156d0",
      "metadata": {
        "id": "c94156d0"
      },
      "source": [
        "## Various operations in RDD's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd59daba",
      "metadata": {
        "id": "cd59daba",
        "outputId": "d478d640-4b94-4f91-e966-251fea42448d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements present in RDD->  7\n"
          ]
        }
      ],
      "source": [
        "# i) count()\n",
        "words = spark.sparkContext.parallelize([\n",
        "    \"Python\", \"Java\", \"Hadoop\", \"C\", \"C++\", \"Spark vs Hadoop\", \"Pyspark and Spark\"\n",
        "])\n",
        "count = words.count()\n",
        "print(\"Number of elements present in RDD-> \" ,count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739c1b0f",
      "metadata": {
        "id": "739c1b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4cb266-0732-4cb1-a351-20f60b33cd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements present in RDD-> \n"
          ]
        }
      ],
      "source": [
        "# ii) collect() this function returns the entire elements in the RDD\n",
        "words = spark.sparkContext.parallelize([\n",
        "    \"Python\", \"Java\", \"Hadoop\", \"C\", \"C++\", \"Spark vs Hadoop\", \"Pyspark and Spark\"\n",
        "])\n",
        "count = words.collect()\n",
        "print(\"Number of elements present in RDD-> \" %(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829aa01d",
      "metadata": {
        "id": "829aa01d"
      },
      "outputs": [],
      "source": [
        "# iii) foreach(f) this function returns only those elements which match the condition of the functions inside foreach\n",
        "words = spark.sparkContext.parallelize([\n",
        "    \"Python\", \"Java\", \"Hadoop\", \"C\", \"C++\", \"Spark vs Hadoop\", \"Pyspark and Spark\"\n",
        "])\n",
        "def f(x):\n",
        "    print(x)\n",
        "    fore = words.foreach(f)\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eaf53f3",
      "metadata": {
        "id": "8eaf53f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8cf5d9-30f1-458e-e14e-aafbcb61df1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 4, 3, 9, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "## iv) Map\n",
        "num = spark.sparkContext.parallelize([5,5,4,3,9,2])\n",
        "num.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae91a67",
      "metadata": {
        "id": "5ae91a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad6acce-3106-42dc-a823-bdbd5b0d83fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 10, 8, 6, 18, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "num.map(lambda a:a*2).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6046550d",
      "metadata": {
        "id": "6046550d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0e7541-4c7b-4265-c218-eab2b18ab304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 25, 16, 9, 81, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "num.map(lambda a:pow(a,2)).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25e1ba0",
      "metadata": {
        "id": "e25e1ba0"
      },
      "outputs": [],
      "source": [
        "#map for strings\n",
        "names = spark.sparkContext.parallelize([\"Dell\",\"HP\",\"Lenovo\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c177c7",
      "metadata": {
        "id": "66c177c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7050c28d-69f8-454a-cca7-48ac4eccbe69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mr. Dell', 'Mr. HP', 'Mr. Lenovo']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "names.map(lambda a: \"Mr. \"+a).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c4b798",
      "metadata": {
        "id": "67c4b798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaeb878-aa71-4af1-efa6-9758dd576d10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 5, 4, 3, 9, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Filter\n",
        "num.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294670f7",
      "metadata": {
        "id": "294670f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa142fa-e5c0-48d6-9f14-cc8bcae0e663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "num.filter(lambda x:x%2==0).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d52bfb",
      "metadata": {
        "id": "44d52bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d0791a-06f6-419f-8cab-d1b6705e9ce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dell', 'HP', 'Lenovo']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "names.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "719eca64",
      "metadata": {
        "id": "719eca64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b9db3c-2289-42f7-f178-9ca8683261d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dell']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "names.filter(lambda x: \"D\" in x).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "4f3a8342",
      "metadata": {
        "id": "4f3a8342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d5e804-20b5-4209-a734-9a5220f12683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 8, 2, 4, 5, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "#Union\n",
        "num2 = spark.sparkContext.parallelize([7,8,2,4,5,1])\n",
        "num2.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c840fc18",
      "metadata": {
        "id": "c840fc18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627e1666-4cbc-4083-b782-2230635849dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 8, 2, 4, 5, 1, 5, 5, 4, 3, 9, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "num2.union(num).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "b96dcb0b",
      "metadata": {
        "id": "b96dcb0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210df78-675c-46e7-b630-95946ea74b86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "type(num2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1466f396",
      "metadata": {
        "id": "1466f396"
      },
      "source": [
        "# PySpark SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18731992",
      "metadata": {
        "id": "18731992"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practise').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a7b91d",
      "metadata": {
        "id": "54a7b91d"
      },
      "outputs": [],
      "source": [
        "## Dataframe\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    Row(a=1, b=2, c=\"Shashank\", d=date(2022,2,9), e=datetime(2022,2,9, 12,0)),\n",
        "    Row(a=2, b=3, c=\"Mihir\", d=date(2022,3,5), e=datetime(2022,3,5, 10,0)),\n",
        "    Row(a=3, b=4, c=\"Pranav\", d=date(2022,4,7), e=datetime(2022,4,7, 5,0))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0c3902",
      "metadata": {
        "id": "1e0c3902",
        "outputId": "ca31d42d-4149-49a4-b371-166f555eca93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: bigint, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae38690",
      "metadata": {
        "id": "dae38690",
        "outputId": "d77fd14a-bbc2-47c1-b5c3-fd97b6193508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+--------+----------+-------------------+\n",
            "|  a|  b|       c|         d|                  e|\n",
            "+---+---+--------+----------+-------------------+\n",
            "|  1|  2|Shashank|2022-02-09|2022-02-09 12:00:00|\n",
            "|  2|  3|   Mihir|2022-03-05|2022-03-05 10:00:00|\n",
            "|  3|  4|  Pranav|2022-04-07|2022-04-07 05:00:00|\n",
            "+---+---+--------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9be47b",
      "metadata": {
        "id": "ea9be47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ce0a28-485e-40c2-8875-b8aedd56ffaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#create the pyspark DataFrame with an explicit schema\n",
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 2, 1, 11, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 3, 1, 12, 0))\n",
        "], schema='a long, b double, c string, d date, e timestamp')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a pyspark dataframe from a pandas dataframe"
      ],
      "metadata": {
        "id": "HbPFryQiBMcm"
      },
      "id": "HbPFryQiBMcm"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "59d2d1fe",
      "metadata": {
        "id": "59d2d1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fd1b18-b54a-4bce-d810-f8afcbc2ca36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   a  b        c           d                   e\n",
            "0  1  2  string1  2000-01-01 2000-01-01 12:00:00\n",
            "1  2  3  string2  2000-02-01 2000-02-01 11:00:00\n",
            "2  3  4  string3  2000-03-01 2000-03-01 12:00:00\n",
            " \n",
            "Spark data frame: \n",
            "DataFrame[a: bigint, b: bigint, c: string, d: date, e: timestamp]\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|  2|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|  3|string2|2000-02-01|2000-02-01 11:00:00|\n",
            "|  3|  4|string3|2000-03-01|2000-03-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pandas_df = pd.DataFrame({\n",
        "    'a':[1,2,3],\n",
        "    'b':[2,3,4],\n",
        "    'c':['string1', 'string2', 'string3'],\n",
        "    'd':[date(2000, 1, 1),  date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'e':[datetime(2000,1,1, 12,0),datetime(2000,2,1, 11,0),datetime(2000,3,1, 12,0)]\n",
        "})\n",
        "print(pandas_df)\n",
        "print(\" \")\n",
        "print(\"Spark data frame: \")\n",
        "spark_df = spark.createDataFrame(pandas_df)\n",
        "print(spark_df)\n",
        "print(spark_df.show())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Pyspark dataframe from an RDD"
      ],
      "metadata": {
        "id": "mQdycXvBBS4G"
      },
      "id": "mQdycXvBBS4G"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "88e94cfa",
      "metadata": {
        "id": "88e94cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725d61be-d6d2-4263-e780-aaac52c0fb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParallelCollectionRDD[80] at readRDDFromFile at PythonRDD.scala:274\n",
            " \n",
            "Pyspark dataframe: \n",
            "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-02-01 11:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-03-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n",
            "None\n",
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "rdd = spark.sparkContext.parallelize([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 2, 1, 11, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 3, 1, 12, 0))             \n",
        "])\n",
        "print(rdd)\n",
        "print(\" \")\n",
        "print(\"Pyspark dataframe: \")\n",
        "spark_df = spark.createDataFrame(rdd, schema = ['a','b','c','d','e'])\n",
        "print(spark_df)\n",
        "print(spark_df.show())\n",
        "print(df.printSchema())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing data"
      ],
      "metadata": {
        "id": "6Z9oRA-dB6qi"
      },
      "id": "6Z9oRA-dB6qi"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "247338e0",
      "metadata": {
        "id": "247338e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e6215b-6c6d-4893-8f35-347c871555e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-02-01 11:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_df.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view rows vertically"
      ],
      "metadata": {
        "id": "5HkhL6sECBo_"
      },
      "id": "5HkhL6sECBo_"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "a642076b",
      "metadata": {
        "id": "a642076b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840f1156-86bc-4c16-cf7b-b16f2f38d1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0------------------\n",
            " a   | 1                   \n",
            " b   | 2.0                 \n",
            " c   | string1             \n",
            " d   | 2000-01-01          \n",
            " e   | 2000-01-01 12:00:00 \n",
            "-RECORD 1------------------\n",
            " a   | 2                   \n",
            " b   | 3.0                 \n",
            " c   | string2             \n",
            " d   | 2000-02-01          \n",
            " e   | 2000-02-01 11:00:00 \n",
            "-RECORD 2------------------\n",
            " a   | 3                   \n",
            " b   | 4.0                 \n",
            " c   | string3             \n",
            " d   | 2000-03-01          \n",
            " e   | 2000-03-01 12:00:00 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(3, vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see schema and column name"
      ],
      "metadata": {
        "id": "2QiAQUaqCK5B"
      },
      "id": "2QiAQUaqCK5B"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "30492db9",
      "metadata": {
        "id": "30492db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9eb522-5ea4-463f-eebd-66d8eafedd95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c', 'd', 'e']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "spark_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "50c991de",
      "metadata": {
        "id": "50c991de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05107dc-2835-4193-b1f1-cd9aff3f6a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show summary of the dataframe"
      ],
      "metadata": {
        "id": "E1oq8s03D_PF"
      },
      "id": "E1oq8s03D_PF"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "34da0e5a",
      "metadata": {
        "id": "34da0e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a315ae81-c3dc-4207-8922-431a1e1fbe3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+---+-------+\n",
            "|summary|  a|  b|      c|\n",
            "+-------+---+---+-------+\n",
            "|  count|  3|  3|      3|\n",
            "|   mean|2.0|3.0|   null|\n",
            "| stddev|1.0|1.0|   null|\n",
            "|    min|  1|2.0|string1|\n",
            "|    max|  3|4.0|string3|\n",
            "+-------+---+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe.collect() -> collects the distributed data to the driver "
      ],
      "metadata": {
        "id": "tiXHasA8Eckj"
      },
      "id": "tiXHasA8Eckj"
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cr9smoeEOeP",
        "outputId": "27aec8d3-467b-4750-a122-1fe752e47651"
      },
      "id": "1Cr9smoeEOeP",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n",
              " Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 2, 1, 11, 0)),\n",
              " Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 3, 1, 12, 0))]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to avoid throwing an out of memory exception we can use dataframe.take() or DataFrame.tail()"
      ],
      "metadata": {
        "id": "KD-r4pLOPFWz"
      },
      "id": "KD-r4pLOPFWz"
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6QF8lZ5EOg_",
        "outputId": "30fdbdf1-1078-4ab1-cfcf-b30731027e9d"
      },
      "id": "-6QF8lZ5EOg_",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n",
              " Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 2, 1, 11, 0))]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TTMFWDSQEOji",
        "outputId": "d3fe96fc-6a0e-4a45-e386-3d6055bcaa46"
      },
      "id": "TTMFWDSQEOji",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d1e5c4c-9b73-4b6d-ad25-36c4c98197b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>string1</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>2000-01-01 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>string2</td>\n",
              "      <td>2000-02-01</td>\n",
              "      <td>2000-02-01 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>string3</td>\n",
              "      <td>2000-03-01</td>\n",
              "      <td>2000-03-01 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d1e5c4c-9b73-4b6d-ad25-36c4c98197b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d1e5c4c-9b73-4b6d-ad25-36c4c98197b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d1e5c4c-9b73-4b6d-ad25-36c4c98197b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   a    b        c           d                   e\n",
              "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
              "1  2  3.0  string2  2000-02-01 2000-02-01 11:00:00\n",
              "2  3  4.0  string3  2000-03-01 2000-03-01 12:00:00"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of column-wise opeartions return Columns"
      ],
      "metadata": {
        "id": "YnjXNCCMyvrQ"
      },
      "id": "YnjXNCCMyvrQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Column\n",
        "from pyspark.sql.functions import upper\n",
        "\n",
        "type(spark_df.c) == type(upper(spark_df.c)) == type(spark_df.c.isNull())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4s1-iA_yzGW",
        "outputId": "db88ec93-1e08-483e-9d09-2535fc86d4be"
      },
      "id": "Y4s1-iA_yzGW",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.select(spark_df.c).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vqCycnyzisw",
        "outputId": "bbbbe9e8-d946-494a-c49c-631c5f302e60"
      },
      "id": "-vqCycnyzisw",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|      c|\n",
            "+-------+\n",
            "|string1|\n",
            "|string2|\n",
            "|string3|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign new column instance"
      ],
      "metadata": {
        "id": "uGiOHrczywRP"
      },
      "id": "uGiOHrczywRP"
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.withColumn('upper_c',upper(spark_df.c)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jbGmV43z27N",
        "outputId": "0a101c81-f9ef-4724-f346-2802121db309"
      },
      "id": "4jbGmV43z27N",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  a|  b|      c|         d|                  e|upper_c|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
            "|  2|3.0|string2|2000-02-01|2000-02-01 11:00:00|STRING2|\n",
            "|  3|4.0|string3|2000-03-01|2000-03-01 12:00:00|STRING3|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To select a subset of rows ,use DataFrame.filter()"
      ],
      "metadata": {
        "id": "YtH6naKKywT-"
      },
      "id": "YtH6naKKywT-"
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.filter(spark_df.c==\"string1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKRoRnGDPXJP",
        "outputId": "d9a95f84-2505-4da2-ae22-1d46cccb7853"
      },
      "id": "vKRoRnGDPXJP",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Applying a function\n",
        "* Pyspark support various UDFs and API to allow users to execute python native function\n",
        "* Pandas UDFs and Pandas Functions APIs"
      ],
      "metadata": {
        "id": "T6rg9Xi8PWiw"
      },
      "id": "T6rg9Xi8PWiw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf ('long')\n",
        "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
        "  #simply pluse one by using pandas series\n",
        "    return series +5\n",
        "spark_df.select(pandas_plus_one(spark_df.b)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzLESSeBPnF2",
        "outputId": "163efea1-0ea4-4b78-c51f-69631b88845e"
      },
      "id": "uzLESSeBPnF2",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|pandas_plus_one(b)|\n",
            "+------------------+\n",
            "|                 7|\n",
            "|                 8|\n",
            "|                 9|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "@pandas_udf('string')\n",
        "def pandas_plus_one(series:pd.Series)->pd.Series:\n",
        "    return series+'hello'\n",
        "spark_df.select(pandas_plus_one(spark_df.c)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPPA3hidPtG3",
        "outputId": "a87de10c-c826-406c-ee74-3f63cfcdc933"
      },
      "id": "lPPA3hidPtG3",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|pandas_plus_one(c)|\n",
            "+------------------+\n",
            "|      string1hello|\n",
            "|      string2hello|\n",
            "|      string3hello|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping Data"
      ],
      "metadata": {
        "id": "1Q85VGSsywXO"
      },
      "id": "1Q85VGSsywXO"
    },
    {
      "cell_type": "code",
      "source": [
        "df =spark.createDataFrame([\n",
        "  ['red','banana',1,10],['blue','banana',2,20],['red','apple',3,30],\n",
        "  ['blue','grape',4,40],['red','apple',5,50],['black','grape',6,60],\n",
        "  ['red','banana',7,70],['red','grape',8,80],['blue','apple',7,80]], schema=['colour','fruit','v1','v2']\n",
        ")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzXzr93WPzGu",
        "outputId": "d1f44d16-a1c2-4379-9e41-d388828be938"
      },
      "id": "uzXzr93WPzGu",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+\n",
            "|colour| fruit| v1| v2|\n",
            "+------+------+---+---+\n",
            "|   red|banana|  1| 10|\n",
            "|  blue|banana|  2| 20|\n",
            "|   red| apple|  3| 30|\n",
            "|  blue| grape|  4| 40|\n",
            "|   red| apple|  5| 50|\n",
            "| black| grape|  6| 60|\n",
            "|   red|banana|  7| 70|\n",
            "|   red| grape|  8| 80|\n",
            "|  blue| apple|  7| 80|\n",
            "+------+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping and then applying the avg() function to the resulting grouping"
      ],
      "metadata": {
        "id": "X8S3lZcjywZn"
      },
      "id": "X8S3lZcjywZn"
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"fruit\").avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Z80KaXP3ou",
        "outputId": "4a929f36-6202-401a-f853-2d87691e1f23"
      },
      "id": "C_Z80KaXP3ou",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+------------------+\n",
            "| fruit|           avg(v1)|           avg(v2)|\n",
            "+------+------------------+------------------+\n",
            "| grape|               6.0|              60.0|\n",
            "| apple|               5.0|53.333333333333336|\n",
            "|banana|3.3333333333333335|33.333333333333336|\n",
            "+------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply a python native function againest each group by using pandas API\n",
        "def pluse_mean(pandas_df):\n",
        "    return pandas_df.assign(v2=pandas_df.v2  - pandas_df.v2.mean()) #for v2 column\n",
        "df.groupby('colour').applyInPandas(pluse_mean , schema=df.schema).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMN8ChAHUeSd",
        "outputId": "8a8469bb-7bc6-4e88-da06-882442df97f9"
      },
      "id": "BMN8ChAHUeSd",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+\n",
            "|colour| fruit| v1| v2|\n",
            "+------+------+---+---+\n",
            "| black| grape|  6|  0|\n",
            "|  blue|banana|  2|-26|\n",
            "|  blue| grape|  4| -6|\n",
            "|  blue| apple|  7| 33|\n",
            "|   red|banana|  1|-38|\n",
            "|   red| apple|  3|-18|\n",
            "|   red| apple|  5|  2|\n",
            "|   red|banana|  7| 22|\n",
            "|   red| grape|  8| 32|\n",
            "+------+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply a python native function againest each group by using pandas API\n",
        "def pluse_mean(pandas_df):\n",
        "    return pandas_df.assign(v1=pandas_df.v1  - pandas_df.v1.mean()) #for v1 column\n",
        "df.groupby('colour').applyInPandas(pluse_mean , schema=df.schema).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDAcfH2NQBDA",
        "outputId": "6288f8c1-4432-42a9-8edc-ac2ae05b1ba5"
      },
      "id": "aDAcfH2NQBDA",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+\n",
            "|colour| fruit| v1| v2|\n",
            "+------+------+---+---+\n",
            "| black| grape|  0| 60|\n",
            "|  blue|banana| -2| 20|\n",
            "|  blue| grape|  0| 40|\n",
            "|  blue| apple|  2| 80|\n",
            "|   red|banana| -3| 10|\n",
            "|   red| apple| -1| 30|\n",
            "|   red| apple|  0| 50|\n",
            "|   red|banana|  2| 70|\n",
            "|   red| grape|  3| 80|\n",
            "+------+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Co-grouping and applying function"
      ],
      "metadata": {
        "id": "OBtBiwn3ywb-"
      },
      "id": "OBtBiwn3ywb-"
    },
    {
      "cell_type": "code",
      "source": [
        "#Co-grouping and applying function\n",
        "df1 = spark.createDataFrame(\n",
        "    [(20000101, 1, 1.0), (20000101, 2, 2.0), (20000102, 1, 3.0), (20000102, 2, 4.0)],\n",
        "    ('time', 'id', 'v1'))\n",
        "\n",
        "df2 = spark.createDataFrame(\n",
        "    [(20000101, 1, 'x'), (20000101, 2, 'y')],\n",
        "    ('time', 'id', 'v2'))\n",
        "\n",
        "def asof_join(l, r):\n",
        "    return pd.merge_asof(l, r, on='time', by='id')\n",
        "\n",
        "df1.groupby('id').cogroup(df2.groupby('id')).applyInPandas(\n",
        "    asof_join, schema='time int, id int, v1 double, v2 string').show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12eDf21HQFLN",
        "outputId": "204f5f4d-0420-41ab-92c5-92f18a6e1ef0"
      },
      "id": "12eDf21HQFLN",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+---+\n",
            "|    time| id| v1| v2|\n",
            "+--------+---+---+---+\n",
            "|20000101|  1|1.0|  x|\n",
            "|20000102|  1|3.0|  x|\n",
            "|20000101|  2|2.0|  y|\n",
            "|20000102|  2|4.0|  y|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting Data in/out\n",
        "#CSV\n",
        "df.write.csv('foo.csv',header=True)\n",
        "spark.read.csv('foo.csv',header=True).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "rij-8Lj0QG42",
        "outputId": "b75ae13d-b711-4f5c-8365-0ab12ec76878"
      },
      "id": "rij-8Lj0QG42",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-255f7f995107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Getting Data in/out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m    953\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0morc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitionBy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: path file:/content/foo.csv already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORC"
      ],
      "metadata": {
        "id": "TzTVgQpPQdom"
      },
      "id": "TzTVgQpPQdom"
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.orc('zoo.orc')\n",
        "spark.read.orc('zoo.orc').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSfuQjx8Qag-",
        "outputId": "0d3959f4-cdfc-4751-b2c5-f5e90bfb5b72"
      },
      "id": "kSfuQjx8Qag-",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+\n",
            "|colour| fruit| v1| v2|\n",
            "+------+------+---+---+\n",
            "|   red| apple|  5| 50|\n",
            "| black| grape|  6| 60|\n",
            "|   red|banana|  7| 70|\n",
            "|   red| grape|  8| 80|\n",
            "|  blue| apple|  7| 80|\n",
            "|   red|banana|  1| 10|\n",
            "|  blue|banana|  2| 20|\n",
            "|   red| apple|  3| 30|\n",
            "|  blue| grape|  4| 40|\n",
            "+------+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parquet"
      ],
      "metadata": {
        "id": "eFEWX1yLQLkR"
      },
      "id": "eFEWX1yLQLkR"
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet('bar.parquet')\n",
        "spark.read.parquet('bar.parquet').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "--MiXhzBQKIn",
        "outputId": "bab2d07c-3883-4779-ac66-9fafe48754f7"
      },
      "id": "--MiXhzBQKIn",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-1c5de3b3f88b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bar.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bar.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineSep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: path file:/content/bar.parquet already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Pandas"
      ],
      "metadata": {
        "id": "kIw8jb9v6_vk"
      },
      "id": "kIw8jb9v6_vk"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/test1.csv\",\"r\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "tb10QDocEOmL",
        "outputId": "0b2327f2-8025-41c2-f7dd-8bedb86a9dea"
      },
      "id": "tb10QDocEOmL",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6fde1880-551d-426b-bccb-149cb0c732db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name,Age,Expe</th>\n",
              "      <th>ience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Shashank,23,10</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mihi</td>\n",
              "      <td>,22,8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P</td>\n",
              "      <td>anav,23,4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fde1880-551d-426b-bccb-149cb0c732db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fde1880-551d-426b-bccb-149cb0c732db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fde1880-551d-426b-bccb-149cb0c732db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Name,Age,Expe      ience\n",
              "0  Shashank,23,10        NaN\n",
              "1            Mihi      ,22,8\n",
              "2               P  anav,23,4"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting and Accessing the data"
      ],
      "metadata": {
        "id": "zC3F7baUR7Jq"
      },
      "id": "zC3F7baUR7Jq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4c153f",
      "metadata": {
        "id": "6d4c153f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbb0740-c33d-4fa5-cce9-d52aeaa1fd73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    2\n",
            "1    4\n",
            "2    5\n",
            "3    6\n",
            "4    7\n",
            "5    8\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#DataSeries\n",
        "#Write a pandas proragm to create and display a one dimensional array like\n",
        "import pandas as pd\n",
        "ds = pd.Series([2,4,5,6,7,8])\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94c4700",
      "metadata": {
        "id": "d94c4700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb995a8-aebc-4004-8f21-9013e8a9b798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas series and type\n",
            "0    5\n",
            "1    2\n",
            "2    1\n",
            "3    4\n",
            "4    6\n",
            "dtype: int64\n",
            "convert pandas series into python list  [5, 2, 1, 4, 6]\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "# Write a pandas prorgam to convert pandas module series to python list and its type\n",
        "import pandas as pd\n",
        "ds = pd.Series([5,2,1,4,6])\n",
        "print(\"pandas series and type\")\n",
        "print(ds)\n",
        "\n",
        "print(\"convert pandas series into python list \", ds.tolist())\n",
        "print(type(ds.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2118e05",
      "metadata": {
        "id": "c2118e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ed8d5e-e1b7-4fb1-d6ab-ef9bcd7b86e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series1: \n",
            "0     2\n",
            "1     4\n",
            "2     6\n",
            "3     8\n",
            "4    10\n",
            "dtype: int64\n",
            "Series2: \n",
            "0     1\n",
            "1     3\n",
            "2     5\n",
            "3     7\n",
            "4    10\n",
            "dtype: int64\n",
            "Compare the elemnts of the said Series:\n",
            "Equals: \n",
            "0    False\n",
            "1    False\n",
            "2    False\n",
            "3    False\n",
            "4     True\n",
            "dtype: bool\n",
            "Greater than: \n",
            "0     True\n",
            "1     True\n",
            "2     True\n",
            "3     True\n",
            "4    False\n",
            "dtype: bool\n",
            "Less than: \n",
            "0    False\n",
            "1    False\n",
            "2    False\n",
            "3    False\n",
            "4    False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "#Write a pandas program to compare the elements of the two pandas series\n",
        "#Sample Series:\n",
        "ds1 = pd.Series([2,4,6,8,10])\n",
        "ds2 = pd.Series([1,3,5,7,10])\n",
        "\n",
        "print(\"Series1: \")\n",
        "print(ds1)\n",
        "print(\"Series2: \")\n",
        "print(ds2)\n",
        "\n",
        "print(\"Compare the elemnts of the said Series:\")\n",
        "print(\"Equals: \")\n",
        "print(ds1==ds2)\n",
        "\n",
        "print(\"Greater than: \")\n",
        "print(ds1>ds2)\n",
        "\n",
        "print(\"Less than: \")\n",
        "print(ds1<ds2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to convert a dictionary to a Pandas series\n",
        "d1 = {'a':100, 'b':200, 'c':300, 'd':400}\n",
        "print(\"Original dictionary: \")\n",
        "print(d1)\n",
        "print(\" \")\n",
        "\n",
        "newSeries = pd.Series(d1)\n",
        "print(\"Converted series: \")\n",
        "print(newSeries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7ZoeL7k6Kj9",
        "outputId": "b2a5a625-eeb5-4683-9fc2-274b3ec8a10f"
      },
      "id": "q7ZoeL7k6Kj9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dictionary: \n",
            "{'a': 100, 'b': 200, 'c': 300, 'd': 400}\n",
            " \n",
            "Converted series: \n",
            "a    100\n",
            "b    200\n",
            "c    300\n",
            "d    400\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to convert a Numpy array to a Pandas series\n",
        "import numpy as np\n",
        "npArray = np.array([10,20,30,40,50])\n",
        "print(\"numpy array is: \")\n",
        "print(npArray)\n",
        "print(\" \")\n",
        "print(\"converted to pandas series \")\n",
        "series = pd.Series(npArray)\n",
        "print(series)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Er5MbPf6iRN",
        "outputId": "1d8965e6-d64f-4f08-e9eb-415f70c0f130"
      },
      "id": "2Er5MbPf6iRN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy array is: \n",
            "[10 20 30 40 50]\n",
            " \n",
            "converted to pandas series \n",
            "0    10\n",
            "1    20\n",
            "2    30\n",
            "3    40\n",
            "4    50\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = pd.Series(['100','200','python','300.12','400'])\n",
        "print(\"Original data series: \")\n",
        "print(s1)\n",
        "print(\"\\nSeries to an array: \")\n",
        "a = np.array(s1.values.tolist())\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2jtF9HL7vF3",
        "outputId": "c40858ff-76d9-4552-8190-e27f1f6648ac"
      },
      "id": "v2jtF9HL7vF3",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data series: \n",
            "0       100\n",
            "1       200\n",
            "2    python\n",
            "3    300.12\n",
            "4       400\n",
            "dtype: object\n",
            "\n",
            "Series to an array: \n",
            "['100' '200' 'python' '300.12' '400']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = pd.Series(['100','200','python','300.12','400'])\n",
        "print(\"Original data series: \")\n",
        "print(s1)\n",
        "print(\"\\nSeries to an array: \")\n",
        "newSeries = s1.sort_values()\n",
        "print(newSeries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcj2mHyK9PRZ",
        "outputId": "ed33ca36-cda6-40d1-fed8-d2f3a432e28e"
      },
      "id": "jcj2mHyK9PRZ",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data series: \n",
            "0       100\n",
            "1       200\n",
            "2    python\n",
            "3    300.12\n",
            "4       400\n",
            "dtype: object\n",
            "\n",
            "Series to an array: \n",
            "0       100\n",
            "1       200\n",
            "3    300.12\n",
            "4       400\n",
            "2    python\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series(data=[1,4,7,5,9], index=['A','B','C','D','E'])\n",
        "print(s)"
      ],
      "metadata": {
        "id": "DyvdtQE7-XUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8b1907-b96a-4165-98f7-caacd7ea00c6"
      },
      "id": "DyvdtQE7-XUI",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    1\n",
            "B    4\n",
            "C    7\n",
            "D    5\n",
            "E    9\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a pandas program to convert the first and last character of each word to upper case in each word of a given series"
      ],
      "metadata": {
        "id": "Ew0U2fO6CSnq"
      },
      "id": "Ew0U2fO6CSnq"
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series(['php','python','java'])\n",
        "print(\"Original series: \")\n",
        "print(s)\n",
        "result = s.map(lambda x: x[0].upper() + x[1:-1] + x[-1].upper())\n",
        "print(\"\\nFirst and last charater of each word to upper case: \")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miVu43zUAhND",
        "outputId": "982628c4-fe34-481a-e89f-cc90c5c0d40c"
      },
      "id": "miVu43zUAhND",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original series: \n",
            "0       php\n",
            "1    python\n",
            "2      java\n",
            "dtype: object\n",
            "\n",
            "First and last charater of each word to upper case: \n",
            "0       PhP\n",
            "1    PythoN\n",
            "2      JavA\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AYTqRC1EF_EW"
      },
      "id": "AYTqRC1EF_EW"
    },
    {
      "cell_type": "code",
      "source": [
        "date_series = pd.Series(['01 Jan 2015', '10-02-2016', '20180307', '2014/05/06', '2016-04-12', '2019-04-06T11:20'])\n",
        "print(\"Original Series:\")\n",
        "print(date_series)\n",
        "print(\"\\nSeries of date strings to a timeseries:\")\n",
        "print(pd.to_datetime(date_series))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtbHIYyZC-U1",
        "outputId": "9506eed6-7215-48ec-b013-8c7f1d138b61"
      },
      "id": "xtbHIYyZC-U1",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Series:\n",
            "0         01 Jan 2015\n",
            "1          10-02-2016\n",
            "2            20180307\n",
            "3          2014/05/06\n",
            "4          2016-04-12\n",
            "5    2019-04-06T11:20\n",
            "dtype: object\n",
            "\n",
            "Series of date strings to a timeseries:\n",
            "0   2015-01-01 00:00:00\n",
            "1   2016-10-02 00:00:00\n",
            "2   2018-03-07 00:00:00\n",
            "3   2014-05-06 00:00:00\n",
            "4   2016-04-12 00:00:00\n",
            "5   2019-04-06 11:20:00\n",
            "dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
        "            'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
        "            'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
        "            'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
        "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
        "\n",
        "df = pd.DataFrame(exam_data , index=labels)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Js8eTY-GEpm",
        "outputId": "b455d5c4-6d11-49cf-fdf2-3e5acaad04b9"
      },
      "id": "6Js8eTY-GEpm",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        name  score  attempts qualify\n",
            "a  Anastasia   12.5         1     yes\n",
            "b       Dima    9.0         3      no\n",
            "c  Katherine   16.5         2     yes\n",
            "d      James    NaN         3      no\n",
            "e      Emily    9.0         2      no\n",
            "f    Michael   20.0         3     yes\n",
            "g    Matthew   14.5         1     yes\n",
            "h      Laura    NaN         1      no\n",
            "i      Kevin    8.0         2      no\n",
            "j      Jonas   19.0         1     yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to display specified column and row\n",
        "print(\"Select specific columns and rows:\")\n",
        "print(df.iloc[[1, 3, 5, 6], [1, 3]])  #1,3,5,6 rows and 1,3 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOpnVCgBLnMF",
        "outputId": "b1c3776d-5515-4eef-efd7-01788b5369ea"
      },
      "id": "JOpnVCgBLnMF",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select specific columns and rows:\n",
            "   score qualify\n",
            "b    9.0      no\n",
            "d    NaN      no\n",
            "f   20.0     yes\n",
            "g   14.5     yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write Pandas program to count the numer of rows and columns of a DataFrame"
      ],
      "metadata": {
        "id": "ijKfQAZnPIFd"
      },
      "id": "ijKfQAZnPIFd"
    },
    {
      "cell_type": "code",
      "source": [
        "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
        "            'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
        "            'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
        "            'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
        "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
        "\n",
        "df = pd.DataFrame(exam_data , index=labels)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riT7i9yZOJV0",
        "outputId": "2b87535f-dde4-436b-cfcf-e50ef080cad3"
      },
      "id": "riT7i9yZOJV0",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        name  score  attempts qualify\n",
            "a  Anastasia   12.5         1     yes\n",
            "b       Dima    9.0         3      no\n",
            "c  Katherine   16.5         2     yes\n",
            "d      James    NaN         3      no\n",
            "e      Emily    9.0         2      no\n",
            "f    Michael   20.0         3     yes\n",
            "g    Matthew   14.5         1     yes\n",
            "h      Laura    NaN         1      no\n",
            "i      Kevin    8.0         2      no\n",
            "j      Jonas   19.0         1     yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of rows and columns of DataFrame\n",
        "total_rows=len(df.axes[0])\n",
        "total_cols=len(df.axes[1])\n",
        "print(\"Number of Rows: \"+str(total_rows))\n",
        "print(\"Number of Columns: \"+str(total_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbmUV8FHPytR",
        "outputId": "430f6972-c20d-417c-ea6d-1768ec8e6425"
      },
      "id": "xbmUV8FHPytR",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows: 10\n",
            "Number of Columns: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the score is between 15 and 20 (inclusive).\n",
        "print(\"Rows where score between 15 and 20 (inclusive):\")\n",
        "print(df[df['score'].between(15, 20)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZzEOkHFRfWN",
        "outputId": "7bee47a9-daa9-4906-8626-02a0181e0f3f"
      },
      "id": "GZzEOkHFRfWN",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows where score between 15 and 20 (inclusive):\n",
            "        name  score  attempts qualify\n",
            "c  Katherine   16.5         2     yes\n",
            "f    Michael   20.0         3     yes\n",
            "j      Jonas   19.0         1     yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum of the examination attempts by the students\n",
        "print(\"\\nSum of the exmaination attempts by the students: \")\n",
        "print(df['attempts'].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaYql5gtRhu0",
        "outputId": "5bb181dd-991f-4b6a-88c5-1f0dd50c2b8a"
      },
      "id": "vaYql5gtRhu0",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sum of the exmaination attempts by the students: \n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n change the name 'james' to 'suresh':  \")\n",
        "df['name'] = df['name'].replace('James','Suresh')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOkaI_L0R0tS",
        "outputId": "8801e8bd-ae06-4ff3-f48d-5ba7218fa820"
      },
      "id": "mOkaI_L0R0tS",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " change the name 'james' to 'suresh':  \n",
            "        name  score  attempts qualify\n",
            "a  Anastasia   12.5         1     yes\n",
            "b       Dima    9.0         3      no\n",
            "c  Katherine   16.5         2     yes\n",
            "d     Suresh    NaN         3      no\n",
            "e      Emily    9.0         2      no\n",
            "f    Michael   20.0         3     yes\n",
            "g    Matthew   14.5         1     yes\n",
            "h      Laura    NaN         1      no\n",
            "i      Kevin    8.0         2      no\n",
            "j      Jonas   19.0         1     yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''.Write a Pandas program to display the default index and set a column as an Index in a given dataframe.\n",
        "\n",
        "Test Data:\n",
        "\n",
        "0        s001     V  Alberto Franco     15/05/2002      35  street1   t1\n",
        "1        s002     V    Gino Mcneill     17/05/2002      32  street2   t2\n",
        "2        s003    VI     Ryan Parkes     16/02/1999      33  street3   t3\n",
        "3        s001    VI    Eesha Hinton     25/09/1998      30  street1   t4\n",
        "4        s002     V    Gino Mcneill     11/05/2002      31  street2   t5\n",
        "5        s004    VI    David Parkes     15/09/1997      32  street4   t6'''\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
        "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
        "print(\"Default Index:\")\n",
        "print(df.head(10))\n",
        "print(\"\\nschool_code as new Index:\")\n",
        "df1 = df.set_index('school_code')\n",
        "print(df1)\n",
        "print(\"\\nt_id as new Index:\")\n",
        "df2 = df.set_index('t_id')\n",
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPt1RL7XVBUw",
        "outputId": "54de83a7-adc6-4c68-c7db-1583125dd559"
      },
      "id": "ZPt1RL7XVBUw",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Index:\n",
            "  school_code class            name date_Of_Birth  weight  address t_id\n",
            "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
            "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
            "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
            "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
            "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
            "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
            "\n",
            "school_code as new Index:\n",
            "            class            name date_Of_Birth  weight  address t_id\n",
            "school_code                                                          \n",
            "s001            V  Alberto Franco    15/05/2002      35  street1   t1\n",
            "s002            V    Gino Mcneill    17/05/2002      32  street2   t2\n",
            "s003           VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
            "s001           VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
            "s002            V    Gino Mcneill    11/05/2002      31  street2   t5\n",
            "s004           VI    David Parkes    15/09/1997      32  street4   t6\n",
            "\n",
            "t_id as new Index:\n",
            "     school_code class            name date_Of_Birth  weight  address\n",
            "t_id                                                                 \n",
            "t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
            "t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
            "t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
            "t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
            "t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
            "t6          s004    VI    David Parkes    15/09/1997      32  street4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to create an index labels by using 64-bit integers, using floating-point numbers in a given dataframe\n",
        "import pandas as pd\n",
        "print(\"Create an Int64Index:\")\n",
        "df_i64 = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=[1, 2, 3, 4, 5, 6])\n",
        "print(df_i64)\n",
        "print(\"\\nView the Index:\")\n",
        "print(df_i64.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePoTs2noWSTu",
        "outputId": "b04ac065-e8b0-45be-827c-756147206976"
      },
      "id": "ePoTs2noWSTu",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create an Int64Index:\n",
            "  school_code class            name date_Of_Birth  weight  address\n",
            "1        s001     V  Alberto Franco    15/05/2002      35  street1\n",
            "2        s002     V    Gino Mcneill    17/05/2002      32  street2\n",
            "3        s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
            "4        s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
            "5        s002     V    Gino Mcneill    11/05/2002      31  street2\n",
            "6        s004    VI    David Parkes    15/09/1997      32  street4\n",
            "\n",
            "View the Index:\n",
            "Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFloating-point labels using Float64Index:\")\n",
        "df_f64 = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=[.1, .2, .3, .4, .5, .6])\n",
        "print(df_f64)\n",
        "print(\"\\nView the Index:\")\n",
        "print(df_f64.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf1mrJWTZYOu",
        "outputId": "02e0c5ef-395c-4c4e-ecc9-89fc6b21fbe0"
      },
      "id": "mf1mrJWTZYOu",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Floating-point labels using Float64Index:\n",
            "    school_code class            name date_Of_Birth   weight  address\n",
            "0.1        s001     V  Alberto Franco     15/05/2002      35  street1\n",
            "0.2        s002     V    Gino Mcneill     17/05/2002      32  street2\n",
            "0.3        s003    VI     Ryan Parkes     16/02/1999      33  street3\n",
            "0.4        s001    VI    Eesha Hinton     25/09/1998      30  street1\n",
            "0.5        s002     V    Gino Mcneill     11/05/2002      31  street2\n",
            "0.6        s004    VI    David Parkes     15/09/1997      32  street4\n",
            "\n",
            "View the Index:\n",
            "Float64Index([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype='float64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to print a DataFrame without index.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_of_birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'weight': [35, 32, 33, 30, 31, 32]},\n",
        "     index =  [1, 2, 3, 4, 5, 6])\n",
        "print(\"Original DataFrame with single index:\")\n",
        "print(df)\n",
        "print(\"\\nDataFrame without index:\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y42phcbZbSj",
        "outputId": "c9bb80b1-3e0b-4837-c0f2-bad209f17bc0"
      },
      "id": "9y42phcbZbSj",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame with single index:\n",
            "  school_code class            name date_of_birth  weight\n",
            "1        s001     V  Alberto Franco    15/05/2002      35\n",
            "2        s002     V    Gino Mcneill    17/05/2002      32\n",
            "3        s003    VI     Ryan Parkes    16/02/1999      33\n",
            "4        s001    VI    Eesha Hinton    25/09/1998      30\n",
            "5        s002     V    Gino Mcneill    11/05/2002      31\n",
            "6        s004    VI    David Parkes    15/09/1997      32\n",
            "\n",
            "DataFrame without index:\n",
            "school_code class           name date_of_birth  weight\n",
            "       s001     V Alberto Franco    15/05/2002      35\n",
            "       s002     V   Gino Mcneill    17/05/2002      32\n",
            "       s003    VI    Ryan Parkes    16/02/1999      33\n",
            "       s001    VI   Eesha Hinton    25/09/1998      30\n",
            "       s002     V   Gino Mcneill    11/05/2002      31\n",
            "       s004    VI   David Parkes    15/09/1997      32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to convert all the string values to upper, lower cases in a given pandas series. Also find the length of the string values.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "s = pd.Series(['X', 'Y', 'Z', 'Aaba', 'Baca', np.nan, 'CABA', 'None', 'bird', 'horse', 'dog'])\n",
        "print(\"Original series:\")\n",
        "print(s)\n",
        "print(\"\\nConvert all string values of the said Series to upper case:\")\n",
        "print(s.str.upper())\n",
        "print(\"\\nConvert all string values of the said Series to lower case:\")\n",
        "print(s.str.lower())\n",
        "print(\"\\nLength of the string values of the said Series:\")\n",
        "print(s.str.len()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdjhFnubZw3b",
        "outputId": "a2f9e504-95ae-4005-e657-79dfdae575c5"
      },
      "id": "DdjhFnubZw3b",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original series:\n",
            "0         X\n",
            "1         Y\n",
            "2         Z\n",
            "3      Aaba\n",
            "4      Baca\n",
            "5       NaN\n",
            "6      CABA\n",
            "7      None\n",
            "8      bird\n",
            "9     horse\n",
            "10      dog\n",
            "dtype: object\n",
            "\n",
            "Convert all string values of the said Series to upper case:\n",
            "0         X\n",
            "1         Y\n",
            "2         Z\n",
            "3      AABA\n",
            "4      BACA\n",
            "5       NaN\n",
            "6      CABA\n",
            "7      NONE\n",
            "8      BIRD\n",
            "9     HORSE\n",
            "10      DOG\n",
            "dtype: object\n",
            "\n",
            "Convert all string values of the said Series to lower case:\n",
            "0         x\n",
            "1         y\n",
            "2         z\n",
            "3      aaba\n",
            "4      baca\n",
            "5       NaN\n",
            "6      caba\n",
            "7      none\n",
            "8      bird\n",
            "9     horse\n",
            "10      dog\n",
            "dtype: object\n",
            "\n",
            "Length of the string values of the said Series:\n",
            "0     1.0\n",
            "1     1.0\n",
            "2     1.0\n",
            "3     4.0\n",
            "4     4.0\n",
            "5     NaN\n",
            "6     4.0\n",
            "7     4.0\n",
            "8     4.0\n",
            "9     5.0\n",
            "10    3.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to remove whitespaces, left sided whitespaces and right sided whitespaces of the string values of a given pandas series.\n",
        "import pandas as pd\n",
        "color1 = pd.Index([' Green', 'Black ', ' Red ', 'White', ' Pink '])\n",
        "print(\"Original series:\")\n",
        "print(color1)\n",
        "print(\"\\nRemove whitespace\")\n",
        "print(color1.str.strip())\n",
        "print(\"\\nRemove left sided whitespace\")\n",
        "print(color1.str.lstrip())\n",
        "print(\"\\nRemove Right sided whitespace\")\n",
        "print(color1.str.rstrip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n02qv7r1bAdj",
        "outputId": "b00c5291-42bf-452d-b3ff-30e6a0bf37ae"
      },
      "id": "n02qv7r1bAdj",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original series:\n",
            "Index([' Green', 'Black ', ' Red ', 'White', ' Pink '], dtype='object')\n",
            "\n",
            "Remove whitespace\n",
            "Index(['Green', 'Black', 'Red', 'White', 'Pink'], dtype='object')\n",
            "\n",
            "Remove left sided whitespace\n",
            "Index(['Green', 'Black ', 'Red ', 'White', 'Pink '], dtype='object')\n",
            "\n",
            "Remove Right sided whitespace\n",
            "Index([' Green', 'Black', ' Red', 'White', ' Pink'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to add leading zeros to the integer column in a pandas series and makes the length of the field to 8 digit.\n",
        "\n",
        "import pandas as pd\n",
        "nums = {'amount': [10, 250, 3000, 40000, 500000]}\n",
        "print(\"Original dataframe:\")\n",
        "df = pd.DataFrame(nums)\n",
        "print(df)\n",
        "print(\"\\nAdd leading zeros:\")\n",
        "df['amount'] = df['amount'].apply(lambda x: '{0:0>8}'.format(x))\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RSwPwifjjeH",
        "outputId": "0724ec7e-5409-4dae-fb20-0d203efe6c42"
      },
      "id": "7RSwPwifjjeH",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe:\n",
            "   amount\n",
            "0      10\n",
            "1     250\n",
            "2    3000\n",
            "3   40000\n",
            "4  500000\n",
            "\n",
            "Add leading zeros:\n",
            "     amount\n",
            "0  00000010\n",
            "1  00000250\n",
            "2  00003000\n",
            "3  00040000\n",
            "4  00500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Pandas program to capitalize all the string values of specified columns of a given DataFrame.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'name': ['alberto','gino','ryan', 'Eesha', 'syed'],\n",
        "    'date_of_birth ': ['17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
        "})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nAfter capitalizing name column:\")\n",
        "df['name'] = list(map(lambda x: x.capitalize(), df['name']))\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m04zYAZUjlHV",
        "outputId": "87fde636-cce6-4c9b-8e88-c164425f5c7e"
      },
      "id": "m04zYAZUjlHV",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      name date_of_birth    age\n",
            "0  alberto     17/05/2002  18.5\n",
            "1     gino     16/02/1999  21.2\n",
            "2     ryan     25/09/1998  22.5\n",
            "3    Eesha     11/05/2002  22.0\n",
            "4     syed     15/09/1997  23.0\n",
            "\n",
            "After capitalizing name column:\n",
            "      name date_of_birth    age\n",
            "0  Alberto     17/05/2002  18.5\n",
            "1     Gino     16/02/1999  21.2\n",
            "2     Ryan     25/09/1998  22.5\n",
            "3    Eesha     11/05/2002  22.0\n",
            "4     Syed     15/09/1997  23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#.Write a Pandas program to replace more than one value with other values in a given DataFrame.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'company_code': ['A','B', 'C', 'D', 'A'],\n",
        "    'date_of_sale': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
        "    'sale_amount': [12348.5, 233331.2, 22.5, 2566552.0, 23.0]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nReplace A with x and D with y:\")\n",
        "df = df.replace([\"A\", \"D\"], [\"X\", \"Y\"])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OZhxgY_jnFe",
        "outputId": "9bb74767-fddd-485c-bd66-7a3bee152587"
      },
      "id": "_OZhxgY_jnFe",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "  company_code date_of_sale  sale_amount\n",
            "0            A   12/05/2002      12348.5\n",
            "1            B   16/02/1999     233331.2\n",
            "2            C   25/09/1998         22.5\n",
            "3            D   12/02/2022    2566552.0\n",
            "4            A   15/09/1997         23.0\n",
            "\n",
            "Replace A with x and D with y:\n",
            "  company_code date_of_sale  sale_amount\n",
            "0            X   12/05/2002      12348.5\n",
            "1            B   16/02/1999     233331.2\n",
            "2            C   25/09/1998         22.5\n",
            "3            Y   12/02/2022    2566552.0\n",
            "4            X   15/09/1997         23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Write a Pandas program to create\n",
        "a) Datetime object for Jan 15 2012.\n",
        "b) Specific date and time of 9:20 pm.\n",
        "c) Local date and time.\n",
        "d) A date without time.\n",
        "e) Current date.\n",
        "f) Time from a datetime.\n",
        "g) Current local time.'''\n",
        "\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Datetime object for Jan 11 2012:\")\n",
        "print(datetime(2012, 1, 11))\n",
        "print(\"\\nSpecific date and time of 9:20 pm\") \n",
        "print(datetime(2011, 1, 11, 21, 20))\n",
        "print(\"\\nLocal date and time:\")\n",
        "print(datetime.now())\n",
        "print(\"\\nA date without time: \")\n",
        "print(datetime.date(datetime(2012, 5, 22)))\n",
        "print(\"\\nCurrent date:\")\n",
        "print(datetime.now().date())\n",
        "print(\"\\nTime from a datetime:\")\n",
        "print(datetime.time(datetime(2012, 12, 15, 18, 12)))\n",
        "print(\"\\nCurrent local time:\") \n",
        "print(datetime.now().time())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfQtMSy0jooW",
        "outputId": "f14c2eb3-cc1d-4523-d70b-da80b31bd757"
      },
      "id": "mfQtMSy0jooW",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datetime object for Jan 11 2012:\n",
            "2012-01-11 00:00:00\n",
            "\n",
            "Specific date and time of 9:20 pm\n",
            "2011-01-11 21:20:00\n",
            "\n",
            "Local date and time:\n",
            "2022-02-10 07:35:15.225072\n",
            "\n",
            "A date without time: \n",
            "2012-05-22\n",
            "\n",
            "Current date:\n",
            "2022-02-10\n",
            "\n",
            "Time from a datetime:\n",
            "18:12:00\n",
            "\n",
            "Current local time:\n",
            "07:35:15.229270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nTLNLiZTjsmx"
      },
      "id": "nTLNLiZTjsmx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "PySpark UNext Mine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}